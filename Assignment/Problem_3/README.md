Write a Python function to implement the maximum function

𝑓 : {𝑥 = (𝑥1, … , 𝑥10) ⁄ 𝑥𝑖 ∈ [−1,1], 𝑥1 + ⋯ + 𝑥9 = 1 − 𝑥10} → ℝ

𝑓(𝑥) = 𝑎1 ∙ 𝑥1 + ⋯ + 𝑎10 ∙ 𝑥10,
where 𝑎 = (𝑎1, … , 𝑎10) is a constant vector provided as input.

Generate 10 elements from the solution space, evaluate them, and display the average value obtained.